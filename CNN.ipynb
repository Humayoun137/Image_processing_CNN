{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84603cc8",
   "metadata": {},
   "source": [
    "# import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a9dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb23676",
   "metadata": {},
   "source": [
    "# load the CIFAR-10 dataset and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3419b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert class labels to one-hot encoded vectors\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2526bac",
   "metadata": {},
   "source": [
    "# define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ff368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a sequential model (a linear stack of layers)\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add a 2D convolutional layer with 32 filters, each of size 3x3, using ReLU activation function\n",
    "# Input shape is (32, 32, 3) representing height, width, and RGB color channels\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# Add a 2D max-pooling layer with pool size 2x2\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another 2D convolutional layer with 64 filters, each of size 3x3, using ReLU activation function\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another 2D max-pooling layer with pool size 2x2\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add a third 2D convolutional layer with 128 filters, each of size 3x3, using ReLU activation function\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Flatten the 2D output to 1D (fully connected layer input)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add a dense (fully connected) layer with 128 units and ReLU activation function\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Add the output layer with 10 units (for 10 classes) and softmax activation function\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c43c87",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9afde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',  # Use the Adam optimizer, which is a popular choice for deep learning tasks\n",
    "    loss='categorical_crossentropy',  # Use categorical cross-entropy as the loss function for multi-class classification\n",
    "    metrics=['accuracy']  # Evaluate the model's performance using accuracy metric during training\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b987b",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01bbaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 101s 127ms/step - loss: 1.5396 - accuracy: 0.4369 - val_loss: 1.2553 - val_accuracy: 0.5447\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 107s 137ms/step - loss: 1.1589 - accuracy: 0.5899 - val_loss: 1.1644 - val_accuracy: 0.5918\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 82s 104ms/step - loss: 0.9888 - accuracy: 0.6519 - val_loss: 1.0119 - val_accuracy: 0.6392\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 109s 140ms/step - loss: 0.8768 - accuracy: 0.6931 - val_loss: 0.9169 - val_accuracy: 0.6805\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 103s 132ms/step - loss: 0.7885 - accuracy: 0.7245 - val_loss: 0.8579 - val_accuracy: 0.7039\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 80s 102ms/step - loss: 0.7133 - accuracy: 0.7497 - val_loss: 0.8736 - val_accuracy: 0.6993\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 100s 128ms/step - loss: 0.6528 - accuracy: 0.7708 - val_loss: 0.8492 - val_accuracy: 0.7071\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 76s 97ms/step - loss: 0.5953 - accuracy: 0.7915 - val_loss: 0.8504 - val_accuracy: 0.7145\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 0.5491 - accuracy: 0.8062 - val_loss: 0.8489 - val_accuracy: 0.7185\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 0.4895 - accuracy: 0.8287 - val_loss: 0.9338 - val_accuracy: 0.6978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1823c32cc70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    x_train,  # Training data (features)\n",
    "    y_train,  # Training labels (true values)\n",
    "    epochs=10,  # Number of times the entire dataset will be passed forward and backward through the neural network\n",
    "    batch_size=64,  # Number of samples used in each iteration for updating the model's weights\n",
    "    validation_data=(x_test, y_test)  # Data used for validation during training (not used for training the model)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed6255",
   "metadata": {},
   "source": [
    "# To predict multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b52dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90d742",
   "metadata": {},
   "source": [
    "# List of paths to the 10 images we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daaeb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = ['a.jpeg', 'b.jpeg', 'c.jpeg', \n",
    "               'd.jpeg', 'de.jpeg', 'f.jpeg',\n",
    "               'h.jpeg', 'p.jpeg', 's.jpeg',\n",
    "               't.jpeg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f7a57d",
   "metadata": {},
   "source": [
    "# Define the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "984b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class labels for CIFAR-10 dataset\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51911a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store predicted class labels\n",
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe4c59",
   "metadata": {},
   "source": [
    "# Iterate through the image paths and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00a15fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 812ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "for img_path in image_paths:\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(32, 32))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Normalize pixel values\n",
    "    predictions = model.predict(img_array) # Make prediction\n",
    "    \n",
    "    #Get the class index with the highest probability\n",
    "    predicted_class_index = np.argmax(predictions[0])\n",
    "    \n",
    "    #Map the class index to the class label\n",
    "    predicted_class_label = classes[predicted_class_index]\n",
    "    \n",
    "    #Append the predicted class label to the list\n",
    "    predicted_labels.append(predicted_class_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e288ec1",
   "metadata": {},
   "source": [
    "# Print the predicted class labels for the 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0120982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 - Predicted class: automobile\n",
      "Image 2 - Predicted class: bird\n",
      "Image 3 - Predicted class: cat\n",
      "Image 4 - Predicted class: dog\n",
      "Image 5 - Predicted class: dog\n",
      "Image 6 - Predicted class: frog\n",
      "Image 7 - Predicted class: horse\n",
      "Image 8 - Predicted class: airplane\n",
      "Image 9 - Predicted class: automobile\n",
      "Image 10 - Predicted class: automobile\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the first 10 predicted class labels and print the results\n",
    "for i in range(10):\n",
    "    print(f\"Image {i+1} - Predicted class: {predicted_labels[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
